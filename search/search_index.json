{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":[" "],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AI-DLC for Claude Code","text":"<p>A structured, adaptive software development workflow that guides AI through disciplined three-phase development.</p> <p> Get Started -- Just run <code>/aidlc</code> and the workflow adapts automatically.</p> <p> View on GitHub -- Apache-2.0 licensed. Adapted from AWS Labs AI-DLC.</p> <p>Origin</p> <p>AI-DLC was originally developed by AWS Labs for Kiro. This plugin adapts the methodology for Claude Code with multi-agent delegation and model tiering.</p>"},{"location":"#what-is-ai-dlc","title":"What is AI-DLC?","text":"<p>AI-DLC (AI-Driven Development Life Cycle) is a methodology that brings structured software engineering discipline to AI-assisted development. Instead of ad-hoc coding, AI-DLC guides the AI through a three-phase lifecycle with human approval gates at every stage.</p>"},{"location":"#why-ai-dlc","title":"Why AI-DLC?","text":"Without AI-DLC With AI-DLC AI jumps straight to coding Structured analysis before implementation No documentation trail Full audit trail with ISO 8601 timestamps One-size-fits-all approach Adaptive depth based on complexity Single model for everything Opus for strategy, Sonnet for execution Hard to resume interrupted work Session continuity via state tracking No approval gates Human-in-the-loop at every stage"},{"location":"#key-features","title":"Key Features","text":"<p>One Command</p> <p>Just run <code>/aidlc</code> and the workflow adapts to your project automatically.</p> <ul> <li> Adaptive Depth -- Simple bug fixes skip unnecessary stages. Complex systems get full architectural treatment.</li> <li> Deep Questioning -- INCEPTION stages ask 15-30 practical questions across mandatory categories with multi-round follow-up. No more shallow Q&amp;A.</li> <li> Three-Phase Lifecycle -- INCEPTION (what and why) \u2192 CONSTRUCTION (how) \u2192 OPERATIONS (deploy and monitor).</li> <li> Human-in-the-Loop -- Every stage requires your explicit approval before proceeding.</li> <li> Multi-Agent Delegation -- Opus handles strategic reasoning, Sonnet handles volume work, Haiku handles fast detection.</li> <li> Parallel Unit Execution -- For multi-unit projects (3+), independent units execute simultaneously in parallel groups, reducing total build time.</li> <li> Full Audit Trail -- Every decision documented with ISO 8601 timestamps.</li> <li> Stage Banners (MOTD) -- Every agent displays a formatted banner on start showing phase, stage number, agent name, model, and capabilities.</li> <li> Session Continuity -- Interrupted workflows can be resumed from where you left off.</li> <li> Brownfield Support -- Deep reverse engineering for existing codebases with 8 analysis artifacts.</li> <li> PR Review -- Standalone utility for analyzing PR diffs across 6 categories (correctness, security, performance, consistency, testing, documentation).</li> <li> CI Setup -- Standalone utility to generate CI/CD pipelines, PR review workflows, and issue/PR templates with automatic tech stack detection.</li> <li> Dependency Graph -- Optional graph-based code dependency analysis with multi-backend support (File/Neo4j/Neptune), impact analysis, Mermaid visualization, PNG export, 9-point deployment verification, CGIG compilation repair, and change-aware test prioritization. E2E verified with Neo4j and Neptune backends.</li> <li> GraphRAG -- Optional summary-based semantic code retrieval. Claude generates module summaries and community structure stored as graph properties -- no external embedding models required. Search by purpose, find related modules, understand code semantics.</li> <li> CGIG Repair -- Compilation-Guided Iterative Graph-retrieval for automated error repair. 4 graph construction methods (Static/CGIG/Lightweight/Hybrid), 10 language-agnostic error categories, confidence-scored fix suggestions from dependency graph context.</li> </ul>"},{"location":"#the-three-phases","title":"The Three Phases","text":""},{"location":"#inception-what-and-why","title":"INCEPTION -- What and Why","text":"<p>Understands the problem space. Detects workspace type, gathers requirements, creates user stories, plans the execution, designs architecture, and decomposes into implementation units.</p> <pre><code>Workspace Detection \u2192 Reverse Engineering \u2192 Requirements Analysis\n\u2192 User Stories \u2192 Workflow Planning \u2192 Application Design \u2192 Units Generation\n</code></pre>"},{"location":"#construction-how","title":"CONSTRUCTION -- How","text":"<p>Implements the system. For each unit (sequentially or in parallel): designs business logic, evaluates non-functional requirements, maps infrastructure, generates code. Finishes with build and test.</p> <pre><code>Per-Unit Loop (sequential or parallel):\n  Functional Design \u2192 NFR Requirements \u2192 NFR Design\n  \u2192 Infrastructure Design \u2192 Code Generation\n\nBuild and Test (after all units)\n</code></pre>"},{"location":"#operations-future","title":"OPERATIONS -- Future","text":"<p>Deployment, monitoring, and operational concerns. Coming in a future release.</p>"},{"location":"#adaptive-execution","title":"Adaptive Execution","text":"<p>Not every stage runs every time. The workflow adapts to your needs:</p> Condition What Happens Simple bug fix Only essential stages: detection, requirements, planning, code gen, test New feature (greenfield) Full INCEPTION + CONSTRUCTION treatment Brownfield modification Adds reverse engineering, adapts scope to existing codebase Infrastructure-only change Skips user stories and functional design <p>Note</p> <p>You can override any recommendation at the Workflow Planning approval gate.</p>"},{"location":"#references","title":"References","text":""},{"location":"#ai-dlc-methodology","title":"AI-DLC Methodology","text":"<ul> <li> AI-DLC Methodology Blog (AWS Tech Blog) -- Original methodology introduction</li> <li> AI-DLC Interactive Demo -- Live demo of the AI-DLC workflow</li> <li> AI-DLC Workflows for Kiro (AWS Labs GitHub) -- Original Kiro steering files</li> </ul>"},{"location":"#code-graph-and-cgig-research","title":"Code Graph and CGIG Research","text":"<p>The CGIG feature (v1.8.0) is based on research from SELENE Lab, Korea University. These papers inform graph-based code generation and repair:</p> <ul> <li> CGIG: Compilation-Guided Iterative Graph-Retrieval for LLM-Based Brownfield Code Generation -- SELENE Lab, Korea University. Reactive compile-parse-query-fix loop achieving 98% compilation success rate on Apache Lucene (1.2M LOC), up from 72% single-shot baseline.</li> <li> Liu et al. (2024). RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph. arXiv:2410.14684. -- Repository-level dependency graph for code completion.</li> <li> Liu et al. (2024). CodeXGraph: Bridging LLMs and Code Repositories via Code Graph Databases. arXiv:2408.05978. -- Graph DB interface for LLM agents to query repository structure.</li> <li> Liu et al. (2024). GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval. arXiv:2406.07003. -- Code graph retrieval with generation integration.</li> <li> Li et al. (2025). GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation. arXiv:2504.10046. -- Structural-Semantic Code Graph (SSCG) for repo-level code generation.</li> <li> Ren et al. (2026). RPG-Encoder: Learning Repository Structure for Code Completion via Graph Encoding. ICSE 2026. -- Incremental graph-based representations of repository evolution.</li> <li> Ke et al. (2025). CGM: Compilation-Guided Code Generation with LLMs. ISSTA 2025. -- Compilation diagnostics to guide iterative code generation.</li> <li> Chen et al. (2024). Teaching Large Language Models to Self-Debug. ICLR 2024. -- LLM self-debugging via execution feedback.</li> <li> Zhong et al. (2024). LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step. ACL 2024. -- Structured debugging with runtime traces.</li> </ul>"},{"location":"commands/","title":"Commands &amp; Agents","text":""},{"location":"commands/#commands","title":"Commands","text":"<p>All commands are prefixed with <code>/aidlc-for-claude:</code> when used in Claude Code.</p>"},{"location":"commands/#main-orchestrator","title":"Main Orchestrator","text":"Command Description <code>/aidlc</code> Entry point. Detects workspace, gathers requirements, executes full workflow"},{"location":"commands/#inception-phase","title":"INCEPTION Phase","text":"Command Stage Description <code>/aidlc-workspace-detection</code> 1 Scan workspace, detect greenfield/brownfield <code>/aidlc-reverse-engineering</code> 2 Analyze existing codebase (brownfield only) <code>/aidlc-requirements-analysis</code> 3 Gather and analyze requirements <code>/aidlc-user-stories</code> 4 Create user stories with INVEST criteria <code>/aidlc-workflow-planning</code> 5 Determine execution plan <code>/aidlc-application-design</code> 6 Component and service layer design <code>/aidlc-units-generation</code> 7 Decompose system into implementation units"},{"location":"commands/#construction-phase","title":"CONSTRUCTION Phase","text":"Command Stage Description <code>/aidlc-system-nfr</code> 0 System-level NFR decisions (multi-unit projects) <code>/aidlc-functional-design</code> 1 Business logic design (per-unit) <code>/aidlc-nfr-requirements</code> 2 Non-functional requirements (per-unit) <code>/aidlc-nfr-design</code> 3 NFR pattern design (per-unit) <code>/aidlc-infrastructure-design</code> 4 Infrastructure mapping (per-unit) <code>/aidlc-code-generation</code> 5 Code + test generation with multi-layer quality gate (per-unit, two-part) <code>/aidlc-build-and-test</code> 6 Build, test (with coverage), security scan, CGIG repair (when enabled), integration tests, and validate"},{"location":"commands/#operations-phase","title":"OPERATIONS Phase","text":"Command Description <code>/aidlc-operations</code> CI/CD pipeline, Dockerfile, .env.example, README, deployment checklist generation"},{"location":"commands/#standalone-utilities","title":"Standalone Utilities","text":"Command Description <code>/aidlc-review-pr</code> Analyze PR diffs for code quality, security, performance, and consistency <code>/aidlc-ci-setup</code> Generate CI/CD pipelines, PR review workflows, and issue/PR templates <code>/aidlc-graph</code> Build, update, visualize, export (PNG), search, repair, verify, or tear down code dependency graphs (File/Neo4j/Neptune) with optional GraphRAG and CGIG"},{"location":"commands/#agents","title":"Agents","text":"<p>Each command delegates to a specialized agent. Agents are tiered by model for cost-efficiency. Every agent displays a stage banner (MOTD) on start showing the current phase, stage number, agent name, model, and key capabilities.</p> <p>Agent Naming</p> <p>Agents use the fully qualified <code>aidlc-for-claude:</code> prefix when invoked via the Task tool.</p>"},{"location":"commands/#opus-agents-strategic-reasoning","title":"Opus Agents (Strategic Reasoning)","text":"Agent Purpose <code>aidlc-for-claude:aidlc-reverse-engineer</code> Deep codebase analysis for brownfield projects <code>aidlc-for-claude:aidlc-requirements-analyst</code> Requirements gathering with 12-category deep questioning (15-25 questions, multi-round) <code>aidlc-for-claude:aidlc-story-writer</code> User story creation with 12-category analysis (error scenarios, edge cases, accessibility, privacy) <code>aidlc-for-claude:aidlc-workflow-planner</code> Execution planning and stage determination <code>aidlc-for-claude:aidlc-application-designer</code> Component and service design with 10-category architecture analysis <code>aidlc-for-claude:aidlc-units-planner</code> System decomposition with parallel group assignment and dependency analysis <code>aidlc-for-claude:aidlc-code-planner</code> Code generation plan with mandatory test plans per module"},{"location":"commands/#sonnet-agents-volume-work","title":"Sonnet Agents (Volume Work)","text":"Agent Purpose <code>aidlc-for-claude:aidlc-functional-designer</code> Business logic and domain model design <code>aidlc-for-claude:aidlc-system-nfr-analyst</code> System-level NFR decisions for multi-unit projects <code>aidlc-for-claude:aidlc-nfr-analyst</code> Non-functional requirements assessment <code>aidlc-for-claude:aidlc-nfr-designer</code> NFR pattern and component design <code>aidlc-for-claude:aidlc-infra-designer</code> Infrastructure service mapping <code>aidlc-for-claude:aidlc-code-generator</code> Code + test generation with lint, type check, and design conformance <code>aidlc-for-claude:aidlc-build-test-engineer</code> Build, test (coverage), security scan, CGIG compilation repair, integration/E2E test scaffolding <code>aidlc-for-claude:aidlc-ops-generator</code> CI/CD, Dockerfile, Docker Compose, .env.example, README, deployment checklist <code>aidlc-for-claude:aidlc-pr-reviewer</code> PR diff analysis for code quality, security, performance, and consistency <code>aidlc-for-claude:aidlc-ci-setup-engineer</code> CI/CD pipeline, PR review workflow, and issue/PR template generation <code>aidlc-for-claude:aidlc-graph-analyzer</code> Code dependency graph with multi-backend support (File/Neo4j/Neptune), 9-point verification, impact analysis, Mermaid visualization, PNG export, GraphRAG summary-based retrieval, and CGIG compilation repair"},{"location":"commands/#haiku-agents-fast-detection","title":"Haiku Agents (Fast Detection)","text":"Agent Purpose <code>aidlc-for-claude:aidlc-workspace-analyst</code> Workspace scanning and project type detection"},{"location":"commands/#two-part-stages","title":"Two-Part Stages","text":"<p>Three stages use a two-part approach for quality assurance:</p> Stage Part 1 (Plan) Part 2 (Execute) User Stories Story plan with personas Individual story generation Units Generation Decomposition plan Unit definition documents Code Generation File-by-file code plan (Opus) Actual code generation (Sonnet) <p>Note</p> <p>In each case, you approve the plan before execution begins.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing! This guide will help you get started.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>Use GitHub Issues to report bugs or suggest features. Please include:</p> <ul> <li>Claude Code version and plugin version</li> <li>Expected vs actual behavior</li> <li>The stage and command where the issue occurred</li> </ul>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>Open an issue with the <code>enhancement</code> label. Describe the use case and reference the relevant workflow stage if applicable.</p>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/your-feature</code>)</li> <li>Make your changes</li> <li>Test locally by installing the plugin from your fork</li> <li>Commit with a clear message</li> <li>Push and open a Pull Request</li> </ol>"},{"location":"contributing/#architecture","title":"Architecture","text":""},{"location":"contributing/#commands-vs-agents","title":"Commands vs Agents","text":"<p>Note</p> <p>Commands define orchestration logic. Agents define execution logic.</p> Layer Directory Responsibility Commands <code>commands/</code> Approval gates, state management, workflow control Agents <code>agents/</code> Step-by-step execution protocols <p>Each command delegates to a corresponding agent via the Task tool.</p>"},{"location":"contributing/#model-tiering","title":"Model Tiering","text":"Tier Model Use For Strategic Opus Requirements, planning, architecture, design decisions Execution Sonnet Functional design, code generation, testing <p>Tip</p> <p>When adding a new agent, choose the tier based on whether the task requires deep reasoning (Opus) or efficient execution (Sonnet).</p>"},{"location":"contributing/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Commands: <code>aidlc-{stage-name}.md</code> (e.g., <code>aidlc-requirements-analysis.md</code>)</li> <li>Agents: <code>aidlc-{role-name}.md</code> (e.g., <code>aidlc-requirements-analyst.md</code>)</li> <li>Agent references in commands: <code>aidlc-for-claude:aidlc-{role-name}</code> (fully qualified with plugin prefix)</li> </ul>"},{"location":"contributing/#local-testing","title":"Local Testing","text":""},{"location":"contributing/#install-from-local-fork","title":"Install from local fork","text":"<p>In the Claude Code chat, add your local fork as a marketplace and install:</p> <pre><code>/plugin marketplace add your-username/aidlc-for-claude\n/plugin install aidlc-for-claude\n</code></pre>"},{"location":"contributing/#test-checklist","title":"Test checklist","text":"<ul> <li>[ ] Command recognition (shows in autocomplete)</li> <li>[ ] Workflow progression (stages execute in order)</li> <li>[ ] Approval gates (user is prompted before each stage)</li> <li>[ ] State management (session can be resumed)</li> <li>[ ] Artifact generation (files created in correct locations)</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache-2.0 License.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>Requirements</p> <p>Claude Code v2.0 or later is required.</p>"},{"location":"getting-started/#step-1-add-marketplace","title":"Step 1: Add Marketplace","text":"<p>In the Claude Code chat, register the marketplace:</p> <pre><code>/plugin marketplace add mateon01/aidlc-for-claude\n</code></pre>"},{"location":"getting-started/#step-2-install","title":"Step 2: Install","text":"<p>Install the plugin from the marketplace:</p> <pre><code>/plugin install aidlc-for-claude\n</code></pre>"},{"location":"getting-started/#step-3-verify","title":"Step 3: Verify","text":"<p>Confirm that <code>aidlc-for-claude</code> is listed as enabled:</p> <pre><code>/plugin list\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>Launch Claude Code in your project directory and run:</p> <pre><code>/aidlc\n</code></pre> <p>Tip</p> <p>That's all you need. The orchestrator handles everything from here.</p> <p>The orchestrator will:</p> <ol> <li>Detect your workspace -- greenfield (empty) or brownfield (existing code)</li> <li>Gather requirements -- ask what you want to build</li> <li>Create an execution plan -- determine which stages are needed (including System NFR for multi-unit projects)</li> <li>Walk through each stage -- with your approval at every step</li> </ol>"},{"location":"getting-started/#brownfield-fast-path","title":"Brownfield Fast Path","text":"<p>When working with an existing codebase, AI-DLC detects it as brownfield and asks about the scope of your change:</p> <ul> <li>Simple change -- Bug fixes, small features, config changes. Skips most analysis stages and goes directly to code generation. Fastest path.</li> <li>Complex change -- Multi-component features or refactoring. Streamlined path that includes requirements analysis but skips user stories.</li> <li>New component -- Greenfield development within an existing repository. Adds a new component to existing system using full structured workflow.</li> <li>Full workflow -- Complete AI-DLC treatment. All stages evaluated based on your project's needs.</li> </ul> <p>Tip</p> <p>For quick bug fixes, choose \"Simple change\" to skip the full analysis pipeline and get to code generation faster.</p>"},{"location":"getting-started/#batch-approval-mode","title":"Batch Approval Mode","text":"<p>After Workflow Planning, AI-DLC offers a batch approval option:</p> <ul> <li>Stage-by-stage (default) -- Review and approve each stage individually</li> <li>Batch approve construction -- Auto-approve all construction design stages (Functional Design through Infrastructure Design), and review only Code Generation and Build &amp; Test results</li> </ul> <p>Tip</p> <p>For large multi-unit projects, batch approval significantly reduces the number of review steps while still giving you control over the most critical stages (code and tests).</p>"},{"location":"getting-started/#running-individual-stages","title":"Running Individual Stages","text":"<p>You can run any stage independently:</p> RequirementsSystem NFRCode GenerationBuild &amp; Test <pre><code>/aidlc-requirements-analysis\n</code></pre> <pre><code>/aidlc-system-nfr\n</code></pre> <pre><code>/aidlc-code-generation\n</code></pre> <pre><code>/aidlc-build-and-test\n</code></pre> <p>Note</p> <p>This is useful when you want to re-run a specific stage or start from a particular point in the workflow.</p>"},{"location":"getting-started/#pr-review","title":"PR Review","text":"<p>AI-DLC includes a standalone PR review utility that can analyze code changes independently of the three-phase workflow.</p> Review a GitHub PRReview Local Changes <pre><code>/aidlc-review-pr\n</code></pre> <p>Select \"Review a GitHub PR\" and provide the PR number. The agent fetches the diff via <code>gh pr diff</code> and performs a 6-category analysis: correctness, security, performance, consistency, testing, and documentation.</p> <pre><code>/aidlc-review-pr\n</code></pre> <p>Select \"Review local changes\" to analyze uncommitted or staged changes in your working directory. Useful for pre-commit review.</p> <p>Tip</p> <p>The PR review agent is read-only -- it analyzes code but does not modify files. No approval gate is required.</p>"},{"location":"getting-started/#ci-setup","title":"CI Setup","text":"<p>Generate CI/CD infrastructure for any project without running the full AI-DLC workflow:</p> <pre><code>/aidlc-ci-setup\n</code></pre> <p>The agent automatically detects your tech stack (language, build system, test framework, linter) and offers to generate:</p> <ul> <li>CI/CD Pipeline -- GitHub Actions or GitLab CI with build, test, lint, and security audit</li> <li>PR Review Workflow -- AI-powered code review using Claude API or OpenAI API</li> <li>Issue Templates -- Feature request and bug report forms customized to your project</li> <li>PR Template -- Standardized pull request description with project-specific checklists</li> </ul> <p>Tip</p> <p>This is the fastest way to add CI/CD to an existing project. No prior AI-DLC stages are required.</p>"},{"location":"getting-started/#graph-analysis","title":"Graph Analysis","text":"<p>Build and visualize code dependency graphs for any project:</p> <pre><code>/aidlc-graph\n</code></pre> <p>The agent detects your project's language (TypeScript/JavaScript, Python, or general) and offers nine modes:</p> <ul> <li>Build graph -- Full static analysis to construct dependency graph from scratch</li> <li>Update graph -- Incrementally update existing graph with recent changes</li> <li>Visualize -- Generate Mermaid diagram from existing graph</li> <li>Export as PNG -- Export dependency graph as PNG images (requires Python matplotlib + networkx)</li> <li>Impact analysis -- Show which modules are affected by recent file changes</li> <li>Search (GraphRAG) -- Find modules by semantic query using summaries and graph context (requires graphRAGEnabled)</li> <li>Repair (CGIG) -- Compilation-Guided Iterative Graph-retrieval for automated error resolution (requires cgigEnabled)</li> <li>Verify -- Test connectivity and data integrity of graph DB</li> <li>Teardown -- Stop graph DB container or clean up cloud resources</li> </ul> <p>Three backends are supported:</p> <ul> <li>Neo4j Local (recommended) -- Docker-based with Cypher queries and browser visualization at localhost:7474</li> <li>AWS Neptune -- AWS managed graph DB with IaC provisioning (CDK/Terraform/CloudFormation) and IAM auth</li> <li>File-based -- Simple JSON file with no external dependencies</li> </ul> <p>Integrated Workflow</p> <p>When using the full AI-DLC workflow (<code>/aidlc</code>), you can opt-in to dependency graph analysis during Workflow Planning. A multi-tier configuration flow lets you choose the backend (Neo4j, Neptune, or File-based) and configure deployment verification. The graph is then automatically maintained throughout the pipeline:</p> <ul> <li>Reverse Engineering builds the initial graph from existing code (brownfield projects)</li> <li>Code Generation updates the graph incrementally per unit with post-update integrity verification (node count, circular dependency check, cross-unit edge resolution)</li> <li>Build &amp; Test uses impact analysis for prioritized test execution -- direct changes first (P1), 1-hop dependents second (P2), then the full suite (P3), and CGIG runs compilation repair loop when cgigEnabled</li> </ul> <p>The orchestrator manages graph DB lifecycle: initialization before the first graph operation, health checks between stages, serialized updates during parallel execution, and a teardown offer at workflow completion. All graph operations are non-blocking -- failures log warnings and continue the workflow. You can retry any graph operation later with <code>/aidlc-graph</code>.</p> <p>GraphRAG (optional): When <code>graphRAGEnabled: true</code> is selected during Workflow Planning, module summaries (purpose, keywords, architectural layer) and community structure are generated alongside the dependency graph. This enables semantic code search via <code>/aidlc-graph search</code> -- finding modules by what they do, not just their file path. No external embedding models or vector databases required.</p> <p>CGIG (optional): When you select a CGIG or Hybrid graph construction method during Workflow Planning, the dependency graph is enriched with class-level properties (constructors, methods, fields, type hierarchy). If compilation fails during Build &amp; Test, a repair loop queries the graph for fix suggestions:</p> <ol> <li>Compilation errors are parsed and classified into 10 categories (cannot_find_symbol, incompatible_types, missing_method, etc.)</li> <li>Per-category graph queries find relevant modules, methods, and type relationships</li> <li>Each suggestion gets a confidence score (0.2--0.9)</li> <li>High-confidence fixes are applied automatically; low-confidence ones are skipped</li> <li>The process repeats until compilation succeeds or max rounds are exhausted</li> </ol> <p>Four graph construction methods are available:</p> <ul> <li>Static (default) -- Standard dependency graph with exports, imports, LOC</li> <li>CGIG -- Enriched with constructors, methods, fields, type hierarchy</li> <li>Lightweight -- Import-only graph, fastest for large codebases</li> <li>Hybrid -- Static base, CGIG enrichment added on-demand when errors occur</li> </ul> <p>Graph Storage</p> <p>File-based graphs are stored in <code>aidlc-docs/graph/dependency-graph.json</code>. Neo4j and Neptune backends store data in the graph database with a local summary at <code>aidlc-docs/graph/graph-summary.md</code>. Mermaid visualizations are generated at <code>aidlc-docs/graph/dependency-graph.md</code>. PNG exports (three views: full graph, community architecture, impact analysis) are saved to <code>aidlc-docs/graph/</code>. Neptune IaC files go to <code>aidlc-docs/graph/infra/</code>.</p> <p>Deployment Verification</p> <p>After graph construction, a 9-point verification suite runs automatically:</p> <ol> <li>Connection test -- DB connectivity and response time</li> <li>Schema validation -- Uniqueness constraints applied</li> <li>Node count -- All modules loaded correctly</li> <li>Edge count -- All import relationships loaded</li> <li>Orphan edge detection -- No edges pointing to non-existent nodes</li> <li>Duplicate edge detection -- No duplicate relationships</li> <li>Hub node analysis -- Identifies critical dependency hubs</li> <li>Circular dependency detection -- Finds import cycles</li> <li>Impact analysis -- Calculates change impact radius for critical modules</li> </ol> <p>Results are saved to <code>aidlc-docs/graph/verification-report.md</code>.</p> <p>Neptune CloudFormation Cleanup</p> <p>When tearing down a Neptune backend provisioned via CloudFormation, stack deletion may be blocked by orphaned VPC Endpoint ENIs or GuardDuty-managed security groups. Delete these resources manually before retrying <code>aws cloudformation delete-stack</code>. Run <code>/aidlc-graph teardown</code> for detailed cleanup commands.</p>"},{"location":"getting-started/#session-continuity","title":"Session Continuity","text":"<p>If your session is interrupted, simply run <code>/aidlc</code> again. The orchestrator detects the existing state file (<code>aidlc-docs/aidlc-state.md</code>) and offers to resume from where you left off.</p>"},{"location":"getting-started/#how-questions-work","title":"How Questions Work","text":"<p>AI-DLC uses a hybrid questioning system to gather thorough requirements:</p> <p>Interactive Q&amp;A (AskUserQuestion) -- For high-impact decisions that need immediate answers:</p> <ul> <li>Tech stack, database, authentication, deployment target, MVP scope</li> <li>Clickable multiple-choice options directly in the terminal</li> <li>Each question offers recommended defaults you can accept with one click</li> </ul> <p>Document-based questionnaires (.md files) -- For detailed analysis requiring thoughtful answers:</p> <ul> <li>Written to <code>aidlc-docs/inception/</code> with <code>[Answer]:</code> tags</li> <li>Organized by mandatory analysis categories (12 for requirements, 10 for design, 12 for stories, 9 for units)</li> <li>Multi-round: Round 1 covers all categories, Round 2 follows up on ambiguities, Round 3 (optional) confirms remaining decisions</li> </ul> <p>Minimum Question Standards</p> <p>INCEPTION agents have mandatory minimums to prevent shallow analysis:</p> Agent Minimum Questions Requirements Analyst 15 (simple) / 20 (moderate) / 25 (complex) Story Writer 10 Application Designer 10 Units Planner 8 <p>All decisions are documented in the <code>aidlc-docs/</code> audit trail with ISO 8601 timestamps.</p>"},{"location":"getting-started/#stage-banners-motd","title":"Stage Banners (MOTD)","text":"<p>Every agent displays a formatted banner when it starts, so you always know which stage is running:</p> <pre><code>AI-DLC | INCEPTION Phase | Stage 3 of 7\n\nRequirements Analysis\n\nAgent: aidlc-requirements-analyst | Model: Opus\n\n12-category deep questioning \u00b7 Multi-round Q&amp;A \u00b7 Hybrid interactive + document\n</code></pre> <p>The banner shows:</p> <ul> <li>Phase (INCEPTION, CONSTRUCTION, or OPERATIONS)</li> <li>Stage number out of total stages in that phase</li> <li>Agent name and model tier (Opus, Sonnet, or Haiku)</li> <li>Key capabilities of that stage</li> </ul> <p>For per-unit CONSTRUCTION stages, the banner also includes the unit name being processed (e.g., \"Functional Design -- <code>auth-service</code>\").</p> <p>The orchestrator displays its own stage banner before delegating to each agent, ensuring banners appear even when agents are run standalone via individual commands like <code>/aidlc-requirements-analysis</code>.</p>"},{"location":"getting-started/#parallel-unit-execution","title":"Parallel Unit Execution","text":"<p>For projects with 3 or more units, AI-DLC offers parallel execution mode during the Construction phase:</p> <ul> <li>Sequential (default) -- One unit at a time, maximum context consistency between units</li> <li>Parallel -- Independent units execute simultaneously in parallel groups, faster completion</li> </ul> <p>Tip</p> <p>The Units Generation stage automatically identifies which units can run in parallel by analyzing inter-unit dependencies. Units are grouped: Group A (no dependencies, start immediately), Group B (depends on Group A), etc.</p> <p>When parallel mode is active:</p> <ul> <li>Each unit's construction pipeline runs as an independent background agent</li> <li>System NFR decisions ensure consistent architectural choices across all units</li> <li>Each unit's code lives in distinct directories to avoid file conflicts</li> <li>Shared files (package.json, docker-compose.yml) are modified only in the final Build &amp; Test phase</li> </ul>"},{"location":"getting-started/#generated-artifacts","title":"Generated Artifacts","text":"<p>All documentation goes to the <code>aidlc-docs/</code> directory. Application code and operational artifacts are placed at your workspace root.</p> <pre><code>aidlc-docs/\n  aidlc-state.md                    # Workflow state tracking\n  audit.md                          # Append-only audit trail\n  graph/\n    dependency-graph.json           # Code dependency graph (when enabled)\n    dependency-graph.md             # Mermaid visualization (when enabled)\n    dependency-graph.png            # Full graph PNG export (export mode)\n    community-architecture.png      # Community view PNG (export mode)\n    impact-analysis.png             # Impact view PNG (export mode)\n    graph-summary.md                # Graph statistics summary (all backends)\n    verification-report.md          # DB verification report (neo4j/neptune)\n    infra/                          # IaC files for Neptune (neptune only)\n  inception/\n    plans/                          # Execution plans\n    reverse-engineering/            # 8 RE artifacts (brownfield)\n    requirements/                   # Requirements + question files\n    user-stories/                   # Stories + personas\n    application-design/             # Components, services, dependencies\n  construction/\n    system-nfr-decisions.md         # System-level NFR (multi-unit projects)\n    plans/                          # Per-unit code plans\n    {unit-name}/\n      functional-design/            # Business logic, rules, entities\n      nfr-requirements/             # Quality attributes, tech stack\n      nfr-design/                   # Patterns, logical components\n      infrastructure-design/        # Service mapping\n      code/                         # Code summaries\n    build-and-test/                 # Build/test instructions + execution report\n  operations/\n    deployment-checklist.md         # Deployment steps and validation\n    developer-readme.md             # Developer onboarding and setup\n\n# Workspace root (application + operational artifacts)\n.env.example                        # Environment configuration template\n.github/workflows/ci.yml            # CI/CD pipeline (or .gitlab-ci.yml)\nDockerfile                          # Container image (conditional)\ndocker-compose.yml                  # Multi-service setup (conditional, multi-unit)\nREADME.md                           # Project README (generated or updated)\ntests/                              # Generated test files alongside application code\n  integration/                      # Integration tests (multi-unit)\n  e2e/                              # E2E test scaffolds (web apps, optional)\n</code></pre> <p>Warning</p> <p>Application code is always generated at the workspace root, never inside <code>aidlc-docs/</code>. The <code>aidlc-docs/</code> directory contains only documentation and workflow artifacts.</p>"},{"location":"workflow/","title":"Workflow Details","text":""},{"location":"workflow/#inception-phase-what-and-why","title":"INCEPTION Phase -- What and Why","text":"<p>The Inception phase establishes what needs to be built and why. It consists of 7 stages.</p>"},{"location":"workflow/#stage-1-workspace-detection","title":"Stage 1: Workspace Detection","text":"<p>Scans the workspace to determine if it's greenfield (new project) or brownfield (existing code). For brownfield projects, this stage also performs a scope assessment -- asking whether the change is a simple fix, a complex modification, a new component within the existing repo, or requires the full structured workflow. This determines the fast path routing.</p>"},{"location":"workflow/#stage-2-reverse-engineering-brownfield-only","title":"Stage 2: Reverse Engineering (Brownfield Only)","text":"<p>For existing codebases, performs deep analysis producing 8 artifacts:</p> Artifact Content Business Overview Domain context and purpose Architecture Map System architecture and patterns Code Structure Directory layout and organization API Inventory Endpoints, interfaces, contracts Component Inventory Modules, services, libraries Tech Stack Languages, frameworks, dependencies Dependency Graph Internal and external dependencies Code Quality Patterns, anti-patterns, tech debt"},{"location":"workflow/#stage-3-requirements-analysis","title":"Stage 3: Requirements Analysis","text":"<p>Gathers and analyzes requirements using a multi-round questioning system across 12 mandatory analysis categories (Business Goals, Target Users, Core Features, User Workflows, Data Model, API/Integration, Security/Compliance, Performance/Scalability, Deployment, Error Handling, Technical Constraints, Timeline). Depth adapts to complexity -- simple projects get minimum 15 questions, moderate projects 20, and complex systems 25+. Follow-up rounds resolve ambiguities and contradictions. Critical decisions (tech stack, deployment target, auth method) use interactive Q&amp;A for immediate response.</p>"},{"location":"workflow/#stage-4-user-stories-conditional","title":"Stage 4: User Stories (Conditional)","text":"<p>Creates user stories following INVEST criteria (Independent, Negotiable, Valuable, Estimable, Small, Testable). Includes persona definition and acceptance criteria. Questions cover 12 mandatory categories including error scenarios, edge cases, accessibility/i18n, and data privacy/consent. Minimum 10 questions required.</p>"},{"location":"workflow/#stage-5-workflow-planning","title":"Stage 5: Workflow Planning","text":"<p>Important</p> <p>This is the critical decision stage. It determines which subsequent stages are needed.</p> <p>Evaluates all gathered context and produces an execution plan. You can override any recommendation.</p> <p>During Workflow Planning, you are offered an opt-in for dependency graph analysis with a multi-tier configuration flow. If you enable graph analysis, you choose a backend:</p> <ul> <li>Neo4j Local (recommended) -- Docker-based with Cypher queries and browser visualization at localhost:7474</li> <li>AWS Neptune -- Managed graph DB with IaC provisioning (CDK, Terraform, or CloudFormation) and IAM auth</li> <li>File-based -- Simple JSON file with no external dependencies</li> </ul> <p>For Neo4j and Neptune backends, additional configuration questions cover ports, persistence, AWS region, instance class, and deployment verification level. When enabled:</p> <ul> <li>Reverse Engineering includes dependency graph construction from existing code</li> <li>Code Generation includes real-time graph updates as code is generated</li> <li>Build &amp; Test includes graph-based impact analysis for test prioritization and deployment verification</li> </ul> <p>The recommendation is context-aware: enabled by default for complex brownfield changes and multi-unit greenfield projects, disabled for simple changes.</p> <p>During Workflow Planning, you also select a graph construction method (Tier 2.25):</p> <ul> <li>Static (default) -- Full AST-based graph with exports, imports, and LOC</li> <li>CGIG -- Class-level enriched with constructors, methods, fields, and type hierarchy -- optimized for compilation error repair</li> <li>Lightweight -- Import-only graph with minimal overhead -- fastest for large codebases</li> <li>Hybrid -- Static base with CGIG reactive expansion on compilation failures</li> </ul> <p>When CGIG or Hybrid is selected, additional configuration covers max repair rounds (default 3) and confidence threshold (default 0.6).</p>"},{"location":"workflow/#graph-construction-methods-in-detail","title":"Graph Construction Methods in Detail","text":"<p>The graph construction method determines what information is extracted from source code and stored as graph node properties. This directly affects which repair strategies are available during Build &amp; Test.</p> Method Nodes Edges Class-Level Properties Best For Static Files + Modules IMPORTS + TESTS Exports, LOC General dependency analysis, impact assessment CGIG Files + Modules IMPORTS + TESTS Exports, LOC, constructors, methods, fields, type hierarchy Compilation error repair, type-aware analysis Lightweight Files only IMPORTS only LOC only Large codebases (500+ files), fast setup Hybrid Static base Static base Static base + CGIG on failure Balanced: fast start, enriched when needed <p>Static is the default and recommended for most projects. It extracts file-level dependencies (imports, exports) and creates a standard dependency graph sufficient for impact analysis and visualization.</p> <p>CGIG enriches each module node with class-level properties:</p> <ul> <li>Constructors: Signatures of all constructors/<code>__init__</code>/factory functions</li> <li>Methods: Method name, parameters, return type, and visibility</li> <li>Fields: Field name, type, and visibility (public/private/protected)</li> <li>Type hierarchy: Extends/implements/traits chain</li> </ul> <p>These properties enable the CGIG repair mode to perform targeted graph queries per error type. For example, a <code>constructor_mismatch</code> error triggers a constructor signature lookup in the graph, while a <code>missing_method</code> error searches the method list across the class hierarchy.</p> <p>Lightweight creates a minimal graph for large codebases where full static analysis would be too slow. It parses only top-level import statements and creates one node per file with no class-level detail. This is 3-5x faster than Static but insufficient for CGIG repair queries.</p> <p>Hybrid starts with a Static graph and reactively enriches specific modules with CGIG properties only when compilation errors occur. This avoids the upfront cost of full CGIG extraction while still enabling repair capabilities on demand.</p>"},{"location":"workflow/#stage-6-application-design-conditional","title":"Stage 6: Application Design (Conditional)","text":"<p>Designs component architecture, service layers, and inter-service dependencies across 10 mandatory categories (Component Identification, Methods, Service Layer, Dependencies, Design Patterns, Scalability, Data Architecture, Security Architecture, Error Handling Strategy, API Design). Minimum 10 questions. Critical architectural choices (monolith vs microservices, DB type, communication pattern) use interactive Q&amp;A. Produces design documents with ASCII diagrams.</p>"},{"location":"workflow/#stage-7-units-generation-conditional","title":"Stage 7: Units Generation (Conditional)","text":"<p>Decomposes the system into implementation units across 9 mandatory categories including team assignment, parallel execution feasibility, and integration points. Each unit includes parallel group metadata (dependency graph, parallel group assignment, integration contracts). For projects with 3+ units, offers parallel execution mode where independent units are processed simultaneously in the Construction phase.</p>"},{"location":"workflow/#construction-phase-how","title":"CONSTRUCTION Phase -- How","text":"<p>The Construction phase implements the system. For multi-unit projects, it begins with system-level NFR assessment, then runs a loop of stages for each unit (sequentially or in parallel), followed by final build and test stages and operations generation.</p> <p>Parallel execution is available for projects with 3+ units. Units with no inter-dependencies are grouped and processed simultaneously. The orchestrator reads the dependency graph from Units Generation and groups units into parallel batches (Group A = no dependencies, Group B = depends on Group A, etc.). Each unit's construction pipeline runs independently with its own approval gates. Shared files are only modified in the final Build &amp; Test phase to avoid conflicts.</p>"},{"location":"workflow/#stage-0-system-nfr-assessment","title":"Stage 0: System NFR Assessment","text":"<p>For projects with 2 or more units, AI-DLC performs a one-time system-level NFR assessment before entering the per-unit loop. This establishes cross-cutting architectural decisions that apply to all units:</p> <ul> <li>Authentication &amp; Authorization -- Session management, token handling, RBAC strategy</li> <li>Observability -- Logging standards, monitoring approach, tracing strategy</li> <li>Error Handling -- Error propagation patterns, retry policies, circuit breakers</li> <li>Data Consistency -- Transaction boundaries, eventual consistency patterns</li> <li>API Conventions -- Versioning strategy, pagination, error response formats</li> </ul> <p>This prevents contradictory choices across units and ensures architectural coherence. Single-unit projects skip this stage and make NFR decisions during the unit's own NFR Requirements stage.</p>"},{"location":"workflow/#per-unit-loop-sequential-or-parallel","title":"Per-Unit Loop (Sequential or Parallel)","text":"<p>For each unit defined in Inception:</p> <p>Cross-unit Context</p> <p>When starting Unit N (where N &gt; 1), the agent receives summaries of all completed units (1 through N-1). This includes functional design summaries, tech stack decisions, shared patterns, and domain entities -- ensuring consistency across the entire system.</p> Step 1: Functional DesignStep 2: NFR RequirementsStep 3: NFR DesignStep 4: Infrastructure DesignStep 5: Code Generation <p>Business logic, domain models, rules, and entities specific to this unit. Reads prior units' artifacts to maintain consistent domain models and conventions.</p> <p>Quality attributes (performance, security, reliability) and technology stack decisions. Maintains consistency with technologies chosen by prior units unless there is a compelling reason to diverge.</p> <p>Patterns and logical components that satisfy the non-functional requirements.</p> <p>Maps logical components to infrastructure services (databases, caches, queues, etc.).</p> <p>Two-part stage:</p> <ol> <li>Planning (Opus) -- Creates a detailed code generation plan with file-by-file breakdown and mandatory test plan per module (test file paths, test cases, assertions, coverage targets)</li> <li>Execution (Sonnet) -- Generates actual application code and test files following the plan</li> </ol> <p>For brownfield projects, a git branch (<code>aidlc/{unit-name}</code>) is created before modifying existing files, providing a safe rollback point.</p> <p>After code generation, a multi-layer quality gate runs:</p> <ul> <li>Type/syntax check (tsc, py_compile, cargo check, go vet)</li> <li>Lint check (ESLint, Ruff, Clippy, golangci-lint) if linter is configured</li> <li>Unit test execution on generated tests</li> <li>Optional design conformance check (verifies code matches design artifacts)</li> </ul> <p>Issues are auto-fixed up to 3 times before presenting results.</p>"},{"location":"workflow/#build-and-test","title":"Build and Test","text":"<p>When dependency graph analysis is enabled (<code>graphEnabled: true</code>), an impact analysis step runs before test execution. It reads the dependency graph, identifies affected modules via BFS/DFS traversal, maps them to test files, and constructs a prioritized test execution plan:</p> <ul> <li>Priority 1 (direct changes): Tests for directly changed files, run first with <code>--bail</code></li> <li>Priority 2 (1-hop dependents): Tests for direct dependents, run second</li> <li>Priority 3 (full suite): All tests to catch transitive effects, run last</li> <li>Modules with no matching test files are flagged as \"untested dependencies\"</li> </ul> <p>Test execution follows priority order. If P1 fails, P2 and P3 still run for completeness. If P1+P2 pass but P3 fails, the report highlights the unexpected transitive effect.</p> <p>When CGIG is enabled (<code>cgigEnabled: true</code>) and compilation fails, a CGIG repair loop runs before test execution. The loop (up to <code>cgigMaxRounds</code>):</p> <ol> <li>Parses compilation errors into 10 language-agnostic categories (cannot_find_symbol, incompatible_types, missing_method, etc.)</li> <li>Queries the dependency graph for repair context using per-error-type strategies</li> <li>Scores each suggestion by confidence (0.2-0.9)</li> <li>Filters by <code>cgigConfidenceThreshold</code> and delegates targeted fixes to the code generator</li> <li>Recompiles and checks -- repeats until success or rounds exhausted</li> </ol> <p>CGIG is non-blocking: failures log warnings and continue to test execution.</p>"},{"location":"workflow/#cgig-error-categories-and-graph-query-strategies","title":"CGIG Error Categories and Graph Query Strategies","text":"<p>The CGIG repair mode classifies compilation errors into 10 language-agnostic categories, each with a specialized graph query strategy:</p> Category Graph Query Strategy Confidence Range <code>cannot_find_symbol</code> 3-tier fuzzy search: exact FQN, then exports, then method/field names 0.4 -- 0.9 <code>incompatible_types</code> Type hierarchy traversal to find common ancestors and valid cast paths 0.5 -- 0.85 <code>missing_method</code> Method search across class hierarchy (current class, superclasses, interfaces) 0.5 -- 0.85 <code>constructor_mismatch</code> Constructor signature lookup in target class node properties 0.7 -- 0.9 <code>missing_import</code> Package/module search by symbol name across all module exports 0.7 -- 0.9 <code>access_violation</code> Visibility check on matched fields/methods 0.5 -- 0.7 <code>missing_override</code> Abstract method search in parent types 0.5 -- 0.85 <code>duplicate_identifier</code> Namespace collision detection across modules 0.4 -- 0.7 <code>circular_dependency</code> Cycle detection in import graph 0.7 -- 0.9 <code>generic_type_error</code> Generic symbol search by referenced names 0.2 -- 0.6 <p>The confidence threshold (default 0.6) filters suggestions before passing them to the code generator. Higher thresholds (0.8) produce fewer but more reliable fixes; lower thresholds (0.4) attempt more aggressive repairs.</p> <p>After all units are complete, generates build instructions and test plans, then executes actual builds and tests. The agent detects the project's build system (npm, pip, cargo, etc.), installs dependencies, runs a dependency security scan, runs the build, executes tests with coverage tracking, and generates integration tests for multi-unit projects. Failed builds are retried up to 3 times with automated fix attempts. For web applications, an optional E2E test scaffold (Playwright/Cypress) can be generated.</p>"},{"location":"workflow/#operations","title":"Operations","text":"<p>Generates operational artifacts at the workspace root and in aidlc-docs:</p> <ol> <li>Deployment Checklist -- Step-by-step deployment guide with environment validation, dependency checks, configuration steps, and smoke test procedures</li> <li>Developer README -- Onboarding guide with setup instructions, development workflow, testing procedures, and troubleshooting tips</li> <li><code>.env.example</code> -- Environment configuration template with all required variables extracted from design artifacts and code</li> <li>CI/CD Pipeline -- GitHub Actions or GitLab CI workflow with install, lint, build, test, and security audit steps</li> <li>Dockerfile (conditional) -- Multi-stage production Dockerfile optimized for the detected stack</li> <li>Docker Compose (conditional, multi-unit) -- Local development stack with all services and dependencies</li> <li>Root README.md -- Project README at workspace root with quick start and architecture overview</li> <li>Monitoring config (conditional) -- Structured logging configuration and health check setup</li> </ol>"},{"location":"workflow/#operations-phase","title":"OPERATIONS Phase","text":"<p>The Operations phase ensures smooth deployment and developer onboarding. It produces both documentation artifacts (in <code>aidlc-docs/operations/</code>) and executable artifacts (at the workspace root) based on the completed construction artifacts. Executable artifacts include CI/CD pipelines, Dockerfiles, environment templates, and README files -- making the generated project immediately deployable and developer-ready.</p>"},{"location":"workflow/#pr-review-workflow","title":"PR Review Workflow","text":"<p>The Operations phase can optionally generate an AI-powered PR review workflow (<code>.github/workflows/pr-review.yml</code>) that automatically reviews pull requests. You choose between Claude API or OpenAI API as the AI backend. The workflow posts a single review comment on each PR with findings organized by category.</p>"},{"location":"workflow/#issue-and-pr-templates","title":"Issue and PR Templates","text":"<p>The Operations phase also generates GitHub issue templates (<code>.github/ISSUE_TEMPLATE/</code>) and a PR template (<code>.github/PULL_REQUEST_TEMPLATE.md</code>) customized to the project's components and conventions. These standardize how contributors report bugs, request features, and describe pull requests.</p>"},{"location":"workflow/#standalone-utilities","title":"Standalone Utilities","text":"<p>These commands can be run independently of the three-phase workflow at any time:</p> Command Description <code>/aidlc-review-pr</code> Analyze PR diffs or local changes for code quality, security, performance, and consistency <code>/aidlc-ci-setup</code> Generate CI/CD pipelines, PR review workflows, and issue/PR templates for any project <code>/aidlc-graph</code> Build, update, visualize, repair, or analyze code dependency graphs <p>The PR review utility performs a 6-category analysis (correctness, security, performance, consistency, testing, documentation) and presents a structured report with per-file findings and a verdict.</p> <p>The CI setup utility detects your project's tech stack automatically and generates selected infrastructure files (CI/CD pipeline, PR review workflow, issue templates, PR template). It also provides branch protection recommendations.</p> <p>The graph analysis utility supports nine modes: build (full static analysis), update (incremental), visualize (Mermaid diagram), export (PNG images via Python networkx+matplotlib), impact analysis (affected module detection with test prioritization), search (GraphRAG semantic code retrieval), repair (CGIG compilation error resolution), verify (9-point DB health check), and teardown (stop/remove graph DB). It supports three backends: File-based JSON, Neo4j (local Docker with Cypher), and AWS Neptune (managed graph DB with IaC provisioning). When GraphRAG is enabled (<code>graphRAGEnabled: true</code>), module summaries (purpose, keywords, architectural layer) and community structure are generated alongside the dependency graph -- no external embedding models required. Neo4j uses full-text indexes for search; File backend uses keyword matching. E2E verified with Neo4j backend on a 15-module TypeScript project -- 15 nodes, 41 edges loaded, all 9 verification checks passed, hub analysis identified critical modules, and impact analysis correctly traced direct and transitive dependencies.</p> <p>All graph node IDs follow a strict normalization convention for consistency across units and queries: <code>u-{NN}</code> for units (lowercase, zero-padded), <code>mod-{kebab-name}</code> for modules, <code>file-{kebab-name}</code> for files, <code>comm-{kebab-name}</code> for communities, and <code>summary-{parent-id}</code> for summaries. IDs are always lowercase, hyphen-separated, and type-prefixed.</p> <p>Automatic Graph Maintenance</p> <p>When using the full AI-DLC workflow with <code>graphEnabled: true</code>, the dependency graph is automatically maintained throughout the pipeline. Reverse Engineering builds the initial graph (brownfield), Code Generation updates it incrementally per unit with post-update integrity verification, and Build &amp; Test uses impact analysis for prioritized test execution. The orchestrator manages graph DB lifecycle -- initialization before the first graph operation, health checks between stages, serialization of updates during parallel execution, and a teardown offer at workflow completion. All graph operations are non-blocking: failures log warnings and continue the workflow. You can retry any graph operation later with <code>/aidlc-graph</code>.</p> <p>Neptune CloudFormation Cleanup</p> <p>When tearing down Neptune via CloudFormation, stack deletion may be blocked by orphaned resources: VPC Endpoint ENIs (persist in private subnets after cluster deletion) and GuardDuty-managed security groups (auto-created if GuardDuty is enabled). Delete these resources manually before retrying <code>aws cloudformation delete-stack</code>. See the graph-analyzer teardown instructions for detailed cleanup commands.</p> <p>Neptune Connectivity \u2014 SSM Run Command Fallback</p> <p>If SSM port forwarding sessions fail with WebSocket timeout errors (<code>context deadline exceeded</code>), use SSM Run Command as an alternative to execute Neptune queries through the bastion host. This approach URL-encodes the Cypher query, sends it via <code>aws ssm send-command</code> to the bastion, where curl forwards it to Neptune's openCypher endpoint, then retrieves the result via <code>aws ssm get-command-invocation</code>. SSM Run Command adds ~5s round-trip latency per query but works reliably when SSM sessions are blocked by network configuration. See the graph-analyzer agent Step 7.3 for detailed commands.</p> <p>Neptune SSM \u2014 Security Group Ingress Requirement</p> <p>When the bastion EC2 and SSM VPC Endpoints share the same security group, the SG must include a self-referencing ingress rule on port 443. Without this, the bastion cannot communicate with SSM VPC Endpoints and the SSM agent will show <code>PingStatus: None</code> indefinitely. CloudFormation templates should include <code>SourceSecurityGroupId: !Ref BastionSecurityGroup</code> in the SecurityGroupIngress for port 443. If SSM agent is stuck, add the rule manually via <code>aws ec2 authorize-security-group-ingress</code> and reboot the instance.</p>"},{"location":"workflow/#stage-execution-matrix","title":"Stage Execution Matrix","text":"Stage Simple Bug Fix Fast Path New Feature Brownfield Infra Change Workspace Detection Reverse Engineering -- -- -- Requirements Analysis -- User Stories -- -- -- Workflow Planning Application Design -- -- -- Units Generation -- -- -- System NFR Assessment* -- -- -- Functional Design -- -- -- NFR Requirements -- -- -- NFR Design -- -- -- Infrastructure Design -- -- Code Generation Build and Test Operations <p>Legend</p> <p> = Always executed |  = Conditional | -- = Skipped</p> <p>* System NFR Assessment only executes when 2+ units are generated</p>"},{"location":"workflow/#stage-banners-motd","title":"Stage Banners (MOTD)","text":"<p>Every agent displays a formatted banner when it starts, showing the current phase, stage number, agent name, model tier, and key capabilities. This provides clear visibility into which stage is running and what to expect. The orchestrator also displays a stage banner before each delegation.</p> <p>For per-unit CONSTRUCTION stages, the banner includes the unit name (e.g., \"Functional Design -- <code>auth-service</code>\"). This ensures clarity even when multiple units are being processed sequentially or in parallel.</p>"},{"location":"workflow/#model-strategy","title":"Model Strategy","text":"<p>AI-DLC uses three model tiers for cost-efficiency:</p> Model Role Used For Opus Strategic reasoning Requirements analysis, architectural decisions, planning, system decomposition Sonnet Volume execution Functional design, NFR analysis, code generation, testing, user stories Haiku Fast detection Workspace scanning, quick project classification"}]}